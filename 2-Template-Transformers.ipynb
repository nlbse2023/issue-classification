{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import gensim\n",
    "import sklearn.metrics\n",
    "import re\n",
    "import unicodedata\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "from simpletransformers.classification import ClassificationModel, ClassificationArgs\n",
    "import wandb\n",
    "import csv\n",
    "from functools import partial\n",
    "import logging\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "transformers_logger = logging.getLogger(\"transformers\")\n",
    "transformers_logger.setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.security.selinux'\n",
      "100  236M  100  236M    0     0  2767k      0  0:01:27  0:01:27 --:--:-- 2676k   0     0  2770k      0  0:01:27  0:00:27  0:01:00 2864k180M    0     0  2761k      0  0:01:27  0:01:06  0:00:21 2721k\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>issue_url</th>\n",
       "      <th>issue_label</th>\n",
       "      <th>issue_created_at</th>\n",
       "      <th>issue_author_association</th>\n",
       "      <th>repository_url</th>\n",
       "      <th>issue_title</th>\n",
       "      <th>issue_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>https://api.github.com/repos/eamodio/vscode-gi...</td>\n",
       "      <td>bug</td>\n",
       "      <td>2021-01-02T18:07:30Z</td>\n",
       "      <td>NONE</td>\n",
       "      <td>https://api.github.com/repos/eamodio/vscode-gi...</td>\n",
       "      <td>Welcome screen on every editor window is very ...</td>\n",
       "      <td>I just discovered Gitlens and find the functio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>https://api.github.com/repos/binwiederhier/pco...</td>\n",
       "      <td>bug</td>\n",
       "      <td>2020-12-31T18:19:31Z</td>\n",
       "      <td>OWNER</td>\n",
       "      <td>https://api.github.com/repos/binwiederhier/pcopy</td>\n",
       "      <td>\"pcopy invite\" and \"pcopy paste abc:\" does not...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>https://api.github.com/repos/binwiederhier/pco...</td>\n",
       "      <td>bug</td>\n",
       "      <td>2021-01-03T04:33:36Z</td>\n",
       "      <td>OWNER</td>\n",
       "      <td>https://api.github.com/repos/binwiederhier/pcopy</td>\n",
       "      <td>UI: Modal overlay is half transparent, shouldn...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>https://api.github.com/repos/Sothatsit/RoyalUr...</td>\n",
       "      <td>enhancement</td>\n",
       "      <td>2020-12-25T00:46:00Z</td>\n",
       "      <td>OWNER</td>\n",
       "      <td>https://api.github.com/repos/Sothatsit/RoyalUr...</td>\n",
       "      <td>Make the loading screen scale with browser win...</td>\n",
       "      <td>Currently the loading wheel is a fixed size in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>https://api.github.com/repos/Malivil/TTT-Custo...</td>\n",
       "      <td>bug</td>\n",
       "      <td>2021-01-02T21:36:57Z</td>\n",
       "      <td>OWNER</td>\n",
       "      <td>https://api.github.com/repos/Malivil/TTT-Custo...</td>\n",
       "      <td>Spectator - Investigate a way to strip weapons...</td>\n",
       "      <td>To bring magneto stick floating</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                          issue_url  issue_label  \\\n",
       "0           0  https://api.github.com/repos/eamodio/vscode-gi...          bug   \n",
       "1           1  https://api.github.com/repos/binwiederhier/pco...          bug   \n",
       "2           2  https://api.github.com/repos/binwiederhier/pco...          bug   \n",
       "3           3  https://api.github.com/repos/Sothatsit/RoyalUr...  enhancement   \n",
       "4           4  https://api.github.com/repos/Malivil/TTT-Custo...          bug   \n",
       "\n",
       "       issue_created_at issue_author_association  \\\n",
       "0  2021-01-02T18:07:30Z                     NONE   \n",
       "1  2020-12-31T18:19:31Z                    OWNER   \n",
       "2  2021-01-03T04:33:36Z                    OWNER   \n",
       "3  2020-12-25T00:46:00Z                    OWNER   \n",
       "4  2021-01-02T21:36:57Z                    OWNER   \n",
       "\n",
       "                                      repository_url  \\\n",
       "0  https://api.github.com/repos/eamodio/vscode-gi...   \n",
       "1   https://api.github.com/repos/binwiederhier/pcopy   \n",
       "2   https://api.github.com/repos/binwiederhier/pcopy   \n",
       "3  https://api.github.com/repos/Sothatsit/RoyalUr...   \n",
       "4  https://api.github.com/repos/Malivil/TTT-Custo...   \n",
       "\n",
       "                                         issue_title  \\\n",
       "0  Welcome screen on every editor window is very ...   \n",
       "1  \"pcopy invite\" and \"pcopy paste abc:\" does not...   \n",
       "2  UI: Modal overlay is half transparent, shouldn...   \n",
       "3  Make the loading screen scale with browser win...   \n",
       "4  Spectator - Investigate a way to strip weapons...   \n",
       "\n",
       "                                          issue_body  \n",
       "0  I just discovered Gitlens and find the functio...  \n",
       "1                                                NaN  \n",
       "2                                                NaN  \n",
       "3  Currently the loading wheel is a fixed size in...  \n",
       "4                    To bring magneto stick floating  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.security.selinux'\n",
      "100 27.2M  100 27.2M    0     0  2154k      0  0:00:12  0:00:12 --:--:-- 2137k\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>issue_url</th>\n",
       "      <th>issue_label</th>\n",
       "      <th>issue_created_at</th>\n",
       "      <th>issue_author_association</th>\n",
       "      <th>repository_url</th>\n",
       "      <th>issue_title</th>\n",
       "      <th>issue_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>https://api.github.com/repos/tlnagy/TIFF.jl/is...</td>\n",
       "      <td>enhancement</td>\n",
       "      <td>2020-04-07T09:08:50Z</td>\n",
       "      <td>NONE</td>\n",
       "      <td>https://api.github.com/repos/tlnagy/TIFF.jl</td>\n",
       "      <td>ERROR: KeyError: key (TIFF.SAMPLEFORMAT_INT, 0...</td>\n",
       "      <td>One more error might need to be caught.\\r\\n`4D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19</td>\n",
       "      <td>https://api.github.com/repos/tisboyo/Twitch_Bo...</td>\n",
       "      <td>enhancement</td>\n",
       "      <td>2020-11-27T07:17:21Z</td>\n",
       "      <td>OWNER</td>\n",
       "      <td>https://api.github.com/repos/tisboyo/Twitch_Bot</td>\n",
       "      <td>Add database backup to dropbox</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>https://api.github.com/repos/DrWhoCares/imgdan...</td>\n",
       "      <td>enhancement</td>\n",
       "      <td>2021-01-02T19:35:34Z</td>\n",
       "      <td>OWNER</td>\n",
       "      <td>https://api.github.com/repos/DrWhoCares/imgdanke</td>\n",
       "      <td>Add a button/method to open the Source or Outp...</td>\n",
       "      <td>Could also add a method to open up path to eac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>https://api.github.com/repos/DrWhoCares/imgdan...</td>\n",
       "      <td>bug</td>\n",
       "      <td>2021-01-02T20:55:34Z</td>\n",
       "      <td>OWNER</td>\n",
       "      <td>https://api.github.com/repos/DrWhoCares/imgdanke</td>\n",
       "      <td>Processes are being started twice</td>\n",
       "      <td>At some point I refactored a few things and en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54</td>\n",
       "      <td>https://api.github.com/repos/Bean-1/AOT/issues/3</td>\n",
       "      <td>bug</td>\n",
       "      <td>2020-12-29T15:34:35Z</td>\n",
       "      <td>OWNER</td>\n",
       "      <td>https://api.github.com/repos/Bean-1/AOT</td>\n",
       "      <td>Cannot add hp to wall</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                          issue_url  issue_label  \\\n",
       "0           6  https://api.github.com/repos/tlnagy/TIFF.jl/is...  enhancement   \n",
       "1          19  https://api.github.com/repos/tisboyo/Twitch_Bo...  enhancement   \n",
       "2          25  https://api.github.com/repos/DrWhoCares/imgdan...  enhancement   \n",
       "3          30  https://api.github.com/repos/DrWhoCares/imgdan...          bug   \n",
       "4          54   https://api.github.com/repos/Bean-1/AOT/issues/3          bug   \n",
       "\n",
       "       issue_created_at issue_author_association  \\\n",
       "0  2020-04-07T09:08:50Z                     NONE   \n",
       "1  2020-11-27T07:17:21Z                    OWNER   \n",
       "2  2021-01-02T19:35:34Z                    OWNER   \n",
       "3  2021-01-02T20:55:34Z                    OWNER   \n",
       "4  2020-12-29T15:34:35Z                    OWNER   \n",
       "\n",
       "                                     repository_url  \\\n",
       "0       https://api.github.com/repos/tlnagy/TIFF.jl   \n",
       "1   https://api.github.com/repos/tisboyo/Twitch_Bot   \n",
       "2  https://api.github.com/repos/DrWhoCares/imgdanke   \n",
       "3  https://api.github.com/repos/DrWhoCares/imgdanke   \n",
       "4           https://api.github.com/repos/Bean-1/AOT   \n",
       "\n",
       "                                         issue_title  \\\n",
       "0  ERROR: KeyError: key (TIFF.SAMPLEFORMAT_INT, 0...   \n",
       "1                     Add database backup to dropbox   \n",
       "2  Add a button/method to open the Source or Outp...   \n",
       "3                  Processes are being started twice   \n",
       "4                              Cannot add hp to wall   \n",
       "\n",
       "                                          issue_body  \n",
       "0  One more error might need to be caught.\\r\\n`4D...  \n",
       "1                                                NaN  \n",
       "2  Could also add a method to open up path to eac...  \n",
       "3  At some point I refactored a few things and en...  \n",
       "4                                                NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# download the training set if it does not exist\n",
    "if not os.path.isfile(\"github-labels-top3-803k-train.csv\"):\n",
    "  !curl \"https://tickettagger.blob.core.windows.net/datasets/github-labels-top3-803k-train.tar.gz\" | tar -xz\n",
    "\n",
    "train_df = pd.read_csv(\"github-labels-top3-803k-train.csv\")\n",
    "display(train_df.head(5))\n",
    "\n",
    "if not os.path.isfile(\"github-labels-top3-803k-test.csv\"):\n",
    "  !curl \"https://tickettagger.blob.core.windows.net/datasets/github-labels-top3-803k-test.tar.gz\" | tar -xz\n",
    "\n",
    "test_df = pd.read_csv(\"github-labels-top3-803k-test.csv\")\n",
    "display(test_df.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_sig_regex = re.compile(r'[a-zA-Z][a-zA-Z0-9_.]*\\([a-zA-Z0-9_, ]*\\)')\n",
    "issue_id_regex = re.compile(r'#[0-9]+')\n",
    "non_ascii_char_regex = re.compile(r'[^\\x00-\\x7f]')\n",
    "\n",
    "def count_tokens(text):\n",
    "\treturn text.count(\" \") + 1\n",
    "\n",
    "def preprocess(text, max_tokens=None):\n",
    "  text = str(text)\n",
    "\n",
    "  # lowercase\n",
    "  text = text.lower()\n",
    "\n",
    "  # replace function signatures\n",
    "  text = function_sig_regex.sub(\" function \", text)\n",
    "\n",
    "  # replace issue ids\n",
    "  text = issue_id_regex.sub(\" issue \", text)\n",
    "  \n",
    "  # remove html tags\n",
    "  text = gensim.parsing.preprocessing.strip_tags(text)\n",
    "  \n",
    "  # remove punctuation\n",
    "  text = gensim.parsing.preprocessing.strip_punctuation(text)\n",
    "  \n",
    "  # remove numerics\n",
    "  text = gensim.parsing.preprocessing.strip_numeric(text)\n",
    "  \n",
    "  # remove non-ascii characters\n",
    "  text = non_ascii_char_regex.sub(\"\", text)\n",
    "  \n",
    "  text = unicodedata.normalize('NFD', text)\n",
    "  \n",
    "  # remove consecutive whitespace characters and convert tabs to spaces\n",
    "  text = gensim.parsing.preprocessing.strip_multiple_whitespaces(text)\n",
    "  \n",
    "  text = gensim.parsing.preprocessing.strip_short(text, minsize=3)\n",
    "  \n",
    "  text = gensim.parsing.preprocessing.remove_stopwords(text)\n",
    "  \n",
    "  # text = gensim.parsing.preprocessing.stem_text(text)\n",
    "  \n",
    "  # limit the number of tokens\n",
    "  if max_tokens is not None:\n",
    "    text = \" \".join(text.split()[:max_tokens])\n",
    "  \n",
    "  return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "248a5985abb2469cbf67342ca9df41cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'title token frequency quantiles'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.500     4.000\n",
       "0.750     6.000\n",
       "0.800     6.000\n",
       "0.850     7.000\n",
       "0.900     8.000\n",
       "0.950     9.000\n",
       "0.990    11.000\n",
       "0.999    17.001\n",
       "Name: issue_title, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1921aa0e49204737876d98f94117ff54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'body token frequency quantiles'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.500      25.000\n",
       "0.750      60.000\n",
       "0.800      74.000\n",
       "0.850      95.000\n",
       "0.900     131.000\n",
       "0.950     226.000\n",
       "0.990     701.120\n",
       "0.999    2831.763\n",
       "Name: issue_body, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "q=[.5, .75, .8, .85, .9, .95, .99, .999]\n",
    "\n",
    "display(\n",
    "\t\"title token frequency quantiles\", \n",
    "\ttrain_df[\"issue_title\"].sample(10_000).progress_apply(preprocess).apply(count_tokens).quantile(q=q)\n",
    ")\n",
    "display(\n",
    "\t\"body token frequency quantiles\", \n",
    "\ttrain_df[\"issue_body\"].sample(10_000).progress_apply(preprocess).apply(count_tokens).quantile(q=q)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_row(row):\n",
    "  doc = \"author \" + row[\"issue_author_association\"].lower()\n",
    "  doc += \" title \" + preprocess(row[\"issue_title\"], max_tokens=18) # 99.9% of titles have <= 18 tokens\n",
    "  doc += \" body \" + preprocess(row[\"issue_body\"], max_tokens=511-count_tokens(doc))\n",
    "\n",
    "  assert count_tokens(doc) <= 512\n",
    "\n",
    "  return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "460ad87409ad49ff8fc51259ffe64962",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transform to simpletransformers format:   0%|          | 0/13102655 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fd34171eb7e4f2187225009e7dc2821",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transform to simpletransformers format:   0%|          | 0/1454863 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# transform dataset into simpletransformers format\n",
    "# https://simpletransformers.ai/docs/classification-data-formats/#multi-class-classification\n",
    "\n",
    "# train_df[\"text\"] = train_df.progress_apply(preprocess_row, axis=1)\n",
    "# train_df[\"labels\"] = pd.Categorical(train_df[\"issue_label\"]).codes\n",
    "# display(train_df[[\"text\", \"labels\"]].head(5))\n",
    "# train_df[[\"text\", \"labels\"]].to_csv(\"train.csv\", index=False)\n",
    "\n",
    "# test_df[\"text\"] = test_df.progress_apply(preprocess_row, axis=1)\n",
    "# test_df[\"labels\"] = pd.Categorical(test_df[\"issue_label\"]).codes\n",
    "# display(test_df[[\"text\", \"labels\"]].head(5))\n",
    "# test_df[[\"text\", \"labels\"]].to_csv(\"test.csv\", index=False)\n",
    "\n",
    "def transform_to_simpletransformers_format(i_path, o_path):\n",
    "\tlabel_map = {\"bug\": 0, \"enhancement\": 1, \"question\": 2}\n",
    "\tn_lines = sum(1 for _ in open(i_path, \"r\"))\n",
    "\n",
    "\twith open(i_path, \"r\") as i_f, open(o_path, \"w\") as o_f:\n",
    "\t\treader = csv.DictReader(i_f)\n",
    "\t\twriter = csv.DictWriter(o_f, fieldnames=[\"text\", \"labels\"])\n",
    "\t\twriter.writeheader()\n",
    "\t\tfor row in tqdm(reader, desc=\"Transform to simpletransformers format\", total=n_lines):\n",
    "\t\t\ttext = preprocess_row(row)\n",
    "\t\t\tlabels = label_map[row[\"issue_label\"]]\n",
    "\t\t\twriter.writerow({\"text\": text, \"labels\": labels})\n",
    "\n",
    "transform_to_simpletransformers_format(\"github-labels-top3-803k-train.csv\", \"train.csv\")\n",
    "transform_to_simpletransformers_format(\"github-labels-top3-803k-test.csv\", \"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.bias', 'lm_head.bias', 'roberta.pooler.dense.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81ad431d1c284fdab920affd9f4fd9a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "INFO:simpletransformers.classification.classification_model: Initializing WandB run for training.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrafaelkallis\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/rafaelkallis/Notebooks/wandb/run-20221106_103843-3fosdnnd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/rafaelkallis/NLBSE%202023%20Template/runs/3fosdnnd\" target=\"_blank\">glorious-donkey-54</a></strong> to <a href=\"https://wandb.ai/rafaelkallis/NLBSE%202023%20Template\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad84cc6aea484f91b7580aa42f9a777a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 4:   0%|          | 0/5648 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/rafaelkallis/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2304: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_args = ClassificationArgs()\n",
    "\n",
    "# https://simpletransformers.ai/docs/classification-specifics/#lazy-loading-data\n",
    "model_args.lazy_loading = True\n",
    "model_args.lazy_delimiter = ','\n",
    "\n",
    "# \n",
    "# https://github.com/ThilinaRajapakse/simpletransformers/issues/225\n",
    "# model_args.use_multiprocessing = False\n",
    "# model_args.use_multiprocessing_for_evaluation = False\n",
    "# model_args.multiprocessing_chunksize = 1\n",
    "# model_args.dataloader_num_workers = 1\n",
    "\n",
    "# model_args.learning_rate = 3e-5 # 4e-5\n",
    "model_args.num_train_epochs = 4 # 1\n",
    "\n",
    "# ~20 for title, ~100 for body\n",
    "model_args.max_seq_length = 128\n",
    "\n",
    "# batch_size = 32 # 5.2GB VRAM\n",
    "# batch_size = 64 # 7.3GB VRAM\n",
    "# batch_size = 96 # 9.4GB VRAM\n",
    "batch_size = 128 # 12GB VRAM\n",
    "model_args.train_batch_size = batch_size\n",
    "model_args.eval_batch_size = batch_size\n",
    "\n",
    "model_args.save_steps = -1\n",
    "# model_args.save_model_every_epoch = False\n",
    "\n",
    "# miscallenous\n",
    "model_args.manual_seed = 0\n",
    "model_args.evaluate_during_training = True\n",
    "model_args.overwrite_output_dir = True\n",
    "model_args.wandb_project = \"NLBSE 2023 Template\"\n",
    "\n",
    "model = ClassificationModel(\n",
    "  'roberta', \n",
    "  'roberta-base', \n",
    "  args=model_args, \n",
    "  num_labels=3\n",
    ")\n",
    "\n",
    "metrics = {\n",
    "  \"p_micro\": partial(sklearn.metrics.precision_score, average='micro'),\n",
    "  \"r_micro\": partial(sklearn.metrics.recall_score, average='micro'),\n",
    "  \"f1_micro\": partial(sklearn.metrics.f1_score, average='micro'),\n",
    "}\n",
    "\n",
    "# model.train_model(train_df=train_df, eval_df=test_df, **metrics)\n",
    "model.train_model(train_df=\"train.csv\", eval_df=\"test.csv\", **metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

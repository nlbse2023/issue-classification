{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Nov 21 16:05:58 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 520.61.05    Driver Version: 520.61.05    CUDA Version: 11.8     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0 Off |                  N/A |\n",
      "| 46%   50C    P5    29W / 170W |      0MiB / 12288MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gensim\n",
    "import sklearn.metrics\n",
    "import re\n",
    "import unicodedata\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from simpletransformers.classification import ClassificationModel, ClassificationArgs\n",
    "import wandb\n",
    "import csv\n",
    "from functools import partial\n",
    "import itertools\n",
    "import random\n",
    "import sys\n",
    "import hashlib\n",
    "import time\n",
    "\n",
    "train_file = 'nlbse23-issue-classification-train.csv'\n",
    "test_file = 'nlbse23-issue-classification-test.csv'\n",
    "\n",
    "csv.field_size_limit(sys.maxsize) # to avoid error: _csv.Error: field larger than field limit (131072)\n",
    "\n",
    "def count_tokens(text):\n",
    "\treturn len(text.split())\n",
    "\n",
    "def count_csv_rows(csv_file):\n",
    "\twith open(csv_file, 'r', newline='', encoding='utf-8') as f:\n",
    "\t\treturn sum(1 for _ in csv.DictReader(f))\n",
    "\n",
    "def print_csv_preview(filename, sep=None):\n",
    "\tprint(filename)\n",
    "\tprint(\"total rows\", count_csv_rows(filename))\n",
    "\tdisplay(pd.read_csv(filename, nrows=5, sep=sep))\n",
    "\n",
    "def sample_csv(file, n_sample):\n",
    "\tn_population = count_csv_rows(file)\n",
    "\tskiprows = random.sample(range(1, n_population), n_population - n_sample)\n",
    "\treturn pd.read_csv(file, skiprows=skiprows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nlbse23-issue-classification-train.csv\n",
      "total rows 1275881\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>labels</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>author_association</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1199051804</td>\n",
       "      <td>documentation</td>\n",
       "      <td>setting a logging Handler name</td>\n",
       "      <td>BPO | [43058](https://bugs.python.org/issue430...</td>\n",
       "      <td>MANNEQUIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1199074324</td>\n",
       "      <td>documentation</td>\n",
       "      <td>Improve documentation for typing._GenericAlias</td>\n",
       "      <td>BPO | [46589](https://bugs.python.org/issue465...</td>\n",
       "      <td>MANNEQUIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1199022454</td>\n",
       "      <td>documentation</td>\n",
       "      <td>Description of '\\w' behavior is vague in `re` ...</td>\n",
       "      <td>BPO | [38566](https://bugs.python.org/issue385...</td>\n",
       "      <td>MANNEQUIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1199028356</td>\n",
       "      <td>documentation</td>\n",
       "      <td>add docstrings to functions in pdb module</td>\n",
       "      <td>BPO | [39278](https://bugs.python.org/issue392...</td>\n",
       "      <td>MANNEQUIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1199055394</td>\n",
       "      <td>documentation</td>\n",
       "      <td>Documentation needs to declare CalledProcessEr...</td>\n",
       "      <td>BPO | [43635](https://bugs.python.org/issue436...</td>\n",
       "      <td>MANNEQUIN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id         labels  \\\n",
       "0  1199051804  documentation   \n",
       "1  1199074324  documentation   \n",
       "2  1199022454  documentation   \n",
       "3  1199028356  documentation   \n",
       "4  1199055394  documentation   \n",
       "\n",
       "                                               title  \\\n",
       "0                     setting a logging Handler name   \n",
       "1     Improve documentation for typing._GenericAlias   \n",
       "2  Description of '\\w' behavior is vague in `re` ...   \n",
       "3          add docstrings to functions in pdb module   \n",
       "4  Documentation needs to declare CalledProcessEr...   \n",
       "\n",
       "                                                body author_association  \n",
       "0  BPO | [43058](https://bugs.python.org/issue430...          MANNEQUIN  \n",
       "1  BPO | [46589](https://bugs.python.org/issue465...          MANNEQUIN  \n",
       "2  BPO | [38566](https://bugs.python.org/issue385...          MANNEQUIN  \n",
       "3  BPO | [39278](https://bugs.python.org/issue392...          MANNEQUIN  \n",
       "4  BPO | [43635](https://bugs.python.org/issue436...          MANNEQUIN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nlbse23-issue-classification-test.csv\n",
      "total rows 142320\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>labels</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>author_association</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1199053386</td>\n",
       "      <td>documentation</td>\n",
       "      <td>A possible misleading expression in the Virtua...</td>\n",
       "      <td>BPO | [43319](https://bugs.python.org/issue433...</td>\n",
       "      <td>MANNEQUIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1255069635</td>\n",
       "      <td>bug</td>\n",
       "      <td>[BUG] a valid `gameName` in the `create a new ...</td>\n",
       "      <td>**Describe the bug**\\r\\nIn the `create a new p...</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1089772715</td>\n",
       "      <td>feature</td>\n",
       "      <td>How to check if a certain entity still exists?</td>\n",
       "      <td>During a bug in my own code I noticed that the...</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000928729</td>\n",
       "      <td>feature</td>\n",
       "      <td>chose the timezone in dbeaver option</td>\n",
       "      <td>Dbeaver 21.2.0\\r\\n\\r\\nFor all version DBeaver,...</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1300011093</td>\n",
       "      <td>bug</td>\n",
       "      <td>[Issue]: Multiple Versions of a Movie not work...</td>\n",
       "      <td>### Please describe your bug\\n\\nThe doc at htt...</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id         labels  \\\n",
       "0  1199053386  documentation   \n",
       "1  1255069635            bug   \n",
       "2  1089772715        feature   \n",
       "3  1000928729        feature   \n",
       "4  1300011093            bug   \n",
       "\n",
       "                                               title  \\\n",
       "0  A possible misleading expression in the Virtua...   \n",
       "1  [BUG] a valid `gameName` in the `create a new ...   \n",
       "2     How to check if a certain entity still exists?   \n",
       "3               chose the timezone in dbeaver option   \n",
       "4  [Issue]: Multiple Versions of a Movie not work...   \n",
       "\n",
       "                                                body author_association  \n",
       "0  BPO | [43319](https://bugs.python.org/issue433...          MANNEQUIN  \n",
       "1  **Describe the bug**\\r\\nIn the `create a new p...               NONE  \n",
       "2  During a bug in my own code I noticed that the...               NONE  \n",
       "3  Dbeaver 21.2.0\\r\\n\\r\\nFor all version DBeaver,...               NONE  \n",
       "4  ### Please describe your bug\\n\\nThe doc at htt...               NONE  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# download the training set if it does not exist\n",
    "if not os.path.isfile(train_file):\n",
    "  !curl \"https://tickettagger.blob.core.windows.net/datasets/{train_file}.tar.gz\" | tar -xz\n",
    "\n",
    "print_csv_preview(train_file)\n",
    "\n",
    "if not os.path.isfile(test_file):\n",
    "  !curl \"https://tickettagger.blob.core.windows.net/datasets/{test_file}.tar.gz\" | tar -xz\n",
    "\n",
    "print_csv_preview(test_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_sig_regex = re.compile(r'[a-zA-Z][a-zA-Z0-9_.]*\\([a-zA-Z0-9_, ]*\\)')\n",
    "issue_id_regex = re.compile(r'#[0-9]+')\n",
    "non_ascii_char_regex = re.compile(r'[^\\x00-\\x7f]')\n",
    "punctuations = '!\\'\"`$%&\\()*,/:;<=>[\\\\]^{|}~+#@-_'\n",
    "punctuations_trans = str.maketrans(punctuations, \" \" * len(punctuations))\n",
    "\n",
    "def preprocess(text, max_tokens=None):\n",
    "  text = str(text)\n",
    "\n",
    "  # replace function signatures\n",
    "  text = function_sig_regex.sub(\" FUNCTION \", text)\n",
    "\n",
    "  # replace issue ids\n",
    "  text = issue_id_regex.sub(\" ISSUE \", text)\n",
    "  \n",
    "  # remove html tags\n",
    "  # text = gensim.parsing.preprocessing.strip_tags(text)\n",
    "  \n",
    "  # remove punctuation\n",
    "  text = text.translate(punctuations_trans)\n",
    "  \n",
    "  # remove numerics\n",
    "  # text = gensim.parsing.preprocessing.strip_numeric(text)\n",
    "  \n",
    "  # remove non-ascii characters\n",
    "  text = non_ascii_char_regex.sub(\"\", text)\n",
    "  \n",
    "  text = unicodedata.normalize('NFD', text)\n",
    "  \n",
    "  # remove consecutive whitespace characters and convert tabs to spaces\n",
    "  text = gensim.parsing.preprocessing.strip_multiple_whitespaces(text)\n",
    "  \n",
    "  # limit the number of tokens\n",
    "  if max_tokens is not None:\n",
    "    text = \" \".join(text.split()[:max_tokens])\n",
    "  \n",
    "  return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'title token count quantiles'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.500     7.0\n",
       "0.750    10.0\n",
       "0.800    10.0\n",
       "0.850    11.0\n",
       "0.900    12.0\n",
       "0.950    15.0\n",
       "0.990    20.0\n",
       "0.999    30.0\n",
       "Name: title, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'body token count quantiles'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.500      72.000\n",
       "0.750     152.000\n",
       "0.800     181.000\n",
       "0.850     223.000\n",
       "0.900     296.000\n",
       "0.950     464.000\n",
       "0.990    1414.030\n",
       "0.999    6433.146\n",
       "Name: body, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_df = sample_csv(train_file, 50_000)\n",
    "\n",
    "q=[.5, .75, .8, .85, .9, .95, .99, .999]\n",
    "\n",
    "display(\"title token count quantiles\", sample_df[\"title\"].apply(preprocess).apply(count_tokens).quantile(q=q))\n",
    "display(\"body token count quantiles\", sample_df[\"body\"].apply(preprocess).apply(count_tokens).quantile(q=q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05b7e48b372242288e44dc9dae3206b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transform to simpletransformers format:   0%|          | 0/1275881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af2fcd516c794659af78b3010124113b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transform to simpletransformers format:   0%|          | 0/142320 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.csv\n",
      "total rows 1275881\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TITLE setting a logging Handler name BODY BPO ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TITLE Improve documentation for typing. Generi...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TITLE Description of w behavior is vague in re...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TITLE add docstrings to functions in pdb modul...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TITLE Documentation needs to declare CalledPro...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  labels\n",
       "0  TITLE setting a logging Handler name BODY BPO ...       3\n",
       "1  TITLE Improve documentation for typing. Generi...       3\n",
       "2  TITLE Description of w behavior is vague in re...       3\n",
       "3  TITLE add docstrings to functions in pdb modul...       3\n",
       "4  TITLE Documentation needs to declare CalledPro...       3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test.csv\n",
      "total rows 142320\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TITLE A possible misleading expression in the ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TITLE BUG a valid gameName in the create a new...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TITLE How to check if a certain entity still e...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TITLE chose the timezone in dbeaver option BOD...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TITLE Issue Multiple Versions of a Movie not w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  labels\n",
       "0  TITLE A possible misleading expression in the ...       3\n",
       "1  TITLE BUG a valid gameName in the create a new...       0\n",
       "2  TITLE How to check if a certain entity still e...       1\n",
       "3  TITLE chose the timezone in dbeaver option BOD...       1\n",
       "4  TITLE Issue Multiple Versions of a Movie not w...       0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# transform dataset into simpletransformers format\n",
    "# https://simpletransformers.ai/docs/classification-data-formats/#multi-class-classification\n",
    "\n",
    "def preprocess_row(row):\n",
    "  doc = \"TITLE \" + preprocess(row[\"title\"], max_tokens=20) # 99% of titles fit\n",
    "  doc += \" BODY \" + preprocess(row[\"body\"], max_tokens=511-count_tokens(doc))\n",
    "\n",
    "  assert count_tokens(doc) <= 512\n",
    "\n",
    "  return doc\n",
    "\n",
    "def transform_to_simpletransformers_format(i_path, o_path):\n",
    "\tlabel_map = {\"bug\": 0, \"feature\": 1, \"question\": 2, \"documentation\": 3 }\n",
    "\n",
    "\twith open(i_path, \"r\") as i_f, open(o_path, \"w\") as o_f:\n",
    "\t\treader = csv.DictReader(i_f)\n",
    "\t\twriter = csv.DictWriter(o_f, fieldnames=[\"text\", \"labels\"], delimiter=\"\\t\")\n",
    "\t\twriter.writeheader()\n",
    "\t\ttotal = count_csv_rows(i_path)\n",
    "\t\tfor row in tqdm(reader, desc=\"Transform to simpletransformers format\", total=total):\n",
    "\t\t\ttext = preprocess_row(row)\n",
    "\t\t\tlabels = label_map[row[\"labels\"]]\n",
    "\t\t\twriter.writerow({\"text\": text, \"labels\": labels})\n",
    "\n",
    "transform_to_simpletransformers_format(train_file, \"train.csv\")\n",
    "transform_to_simpletransformers_format(test_file, \"test.csv\")\n",
    "\n",
    "print_csv_preview(\"train.csv\", sep='\\t')\n",
    "print_csv_preview(\"test.csv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def model_args():\n",
    "  timestamp = str(int(time.time()))\n",
    "\n",
    "  # https://simpletransformers.ai/docs/usage/#configuring-a-simple-transformers-model\n",
    "  args = ClassificationArgs()\n",
    "\n",
    "  args.max_seq_length = 224\n",
    "  args.learning_rate = 1e-4 # 4e-5\n",
    "  args.num_train_epochs = 8\n",
    "  args.train_batch_size = 64\n",
    "  args.eval_batch_size = 64\n",
    "  args.gradient_accumulation_steps = 4\n",
    "\n",
    "  # custom evaluation metric\n",
    "  # https://github.com/ThilinaRajapakse/simpletransformers/discussions/911\n",
    "  args.use_early_stopping = False\n",
    "  args.early_stopping_metric = \"f1_micro\"\n",
    "  args.early_stopping_metric_minimize = False\n",
    "\n",
    "  # evaluate at end of each epoch\n",
    "  args.evaluate_during_training = True\n",
    "  args.evaluate_during_training_steps = int(1e20) # never\n",
    "  # args.evaluate_during_training_steps = 1.5  * 60 * 60 // args.gradient_accumulation_steps # target 1h\n",
    "\n",
    "  # https://simpletransformers.ai/docs/classification-specifics/#lazy-loading-data\n",
    "  args.lazy_loading = True\n",
    "\n",
    "  args.save_steps = -1\n",
    "  args.logging_steps = max(1, 1.6 * 30 // args.gradient_accumulation_steps) # target 30s\n",
    "  args.manual_seed = 0\n",
    "\n",
    "  args.output_dir = f\"outputs/{timestamp}\"\n",
    "  args.best_model_dir = f\"{args.output_dir}/best_model\"\n",
    "\n",
    "  # https://docs.wandb.ai/guides/integrations/other/simpletransformers\n",
    "  # https://simpletransformers.ai/docs/tips-and-tricks/#visualization-support\n",
    "  args.wandb_project = \"NLBSE'23 Issue Report Classification\"\n",
    "  args.wandb_kwargs = {\"entity\": \"nlbse\", \"notes\": f\"timestamp:{timestamp}\"}\n",
    "\n",
    "  return args\n",
    "\n",
    "metrics = {\n",
    "  \"precision_bug\": partial(sklearn.metrics.precision_score, average=None, labels=[0]),\n",
    "  \"recall_bug\": partial(sklearn.metrics.recall_score, average=None, labels=[0]),\n",
    "  \"f1_bug\": partial(sklearn.metrics.f1_score, average=None, labels=[0]),\n",
    "\n",
    "  \"precision_feature\": partial(sklearn.metrics.precision_score, average=None, labels=[1]),\n",
    "  \"recall_feature\": partial(sklearn.metrics.recall_score, average=None, labels=[1]),\n",
    "  \"f1_feature\": partial(sklearn.metrics.f1_score, average=None, labels=[1]),\n",
    "\n",
    "  \"precision_question\": partial(sklearn.metrics.precision_score, average=None, labels=[2]),\n",
    "  \"recall_question\": partial(sklearn.metrics.recall_score, average=None, labels=[2]),\n",
    "  \"f1_question\": partial(sklearn.metrics.f1_score, average=None, labels=[2]),\n",
    "\n",
    "  \"precision_documentation\": partial(sklearn.metrics.precision_score, average=None, labels=[3]),\n",
    "  \"recall_documentation\": partial(sklearn.metrics.recall_score, average=None, labels=[3]),\n",
    "  \"f1_documentation\": partial(sklearn.metrics.f1_score, average=None, labels=[3]),\n",
    "\n",
    "  \"precision_micro\": partial(sklearn.metrics.precision_score, average='micro'),\n",
    "  \"recall_micro\": partial(sklearn.metrics.recall_score, average='micro'),\n",
    "  \"f1_micro\": partial(sklearn.metrics.f1_score, average='micro'),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'roberta.pooler.dense.weight', 'lm_head.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98e7fe7f37c64480aecf4ff2b49ea6b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrafaelkallis\u001b[0m (\u001b[33mnlbse\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/rafaelkallis/Notebooks/wandb/run-20221121_160617-214v1zh5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nlbse/NLBSE%2723%20Issue%20Report%20Classification/runs/214v1zh5\" target=\"_blank\">apricot-water-22</a></strong> to <a href=\"https://wandb.ai/nlbse/NLBSE%2723%20Issue%20Report%20Classification\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc2d9b49c7e94878b2ef613909424829",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 8:   0%|          | 0/19936 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/rafaelkallis/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2323: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 86.00 MiB (GPU 0; 11.77 GiB total capacity; 10.36 GiB already allocated; 72.25 MiB free; 10.76 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m/home/rafaelkallis/issue-classification/3-Template-RoBERTa.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/rafaelkallis/issue-classification/3-Template-RoBERTa.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m ClassificationModel(\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/rafaelkallis/issue-classification/3-Template-RoBERTa.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m   \u001b[39m'\u001b[39m\u001b[39mroberta\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[1;32m      <a href='vscode-notebook-cell:/home/rafaelkallis/issue-classification/3-Template-RoBERTa.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m   \u001b[39m'\u001b[39m\u001b[39mroberta-base\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[1;32m      <a href='vscode-notebook-cell:/home/rafaelkallis/issue-classification/3-Template-RoBERTa.ipynb#X13sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m   args\u001b[39m=\u001b[39mmodel_args(), \n\u001b[1;32m      <a href='vscode-notebook-cell:/home/rafaelkallis/issue-classification/3-Template-RoBERTa.ipynb#X13sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m   num_labels\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/rafaelkallis/issue-classification/3-Template-RoBERTa.ipynb#X13sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m )\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/rafaelkallis/issue-classification/3-Template-RoBERTa.ipynb#X13sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m model\u001b[39m.\u001b[39mtrain_model(train_df\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtrain.csv\u001b[39m\u001b[39m\"\u001b[39m, eval_df\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtest.csv\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmetrics)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/simpletransformers/classification/classification_model.py:632\u001b[0m, in \u001b[0;36mClassificationModel.train_model\u001b[0;34m(self, train_df, multi_label, output_dir, show_running_loss, args, eval_df, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    623\u001b[0m train_dataloader \u001b[39m=\u001b[39m DataLoader(\n\u001b[1;32m    624\u001b[0m     train_dataset,\n\u001b[1;32m    625\u001b[0m     sampler\u001b[39m=\u001b[39mtrain_sampler,\n\u001b[1;32m    626\u001b[0m     batch_size\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mtrain_batch_size,\n\u001b[1;32m    627\u001b[0m     num_workers\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mdataloader_num_workers,\n\u001b[1;32m    628\u001b[0m )\n\u001b[1;32m    630\u001b[0m os\u001b[39m.\u001b[39mmakedirs(output_dir, exist_ok\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m--> 632\u001b[0m global_step, training_details \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain(\n\u001b[1;32m    633\u001b[0m     train_dataloader,\n\u001b[1;32m    634\u001b[0m     output_dir,\n\u001b[1;32m    635\u001b[0m     multi_label\u001b[39m=\u001b[39;49mmulti_label,\n\u001b[1;32m    636\u001b[0m     show_running_loss\u001b[39m=\u001b[39;49mshow_running_loss,\n\u001b[1;32m    637\u001b[0m     eval_df\u001b[39m=\u001b[39;49meval_df,\n\u001b[1;32m    638\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m    639\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    640\u001b[0m )\n\u001b[1;32m    642\u001b[0m \u001b[39m# model_to_save = self.model.module if hasattr(self.model, \"module\") else self.model\u001b[39;00m\n\u001b[1;32m    643\u001b[0m \u001b[39m# model_to_save.save_pretrained(output_dir)\u001b[39;00m\n\u001b[1;32m    644\u001b[0m \u001b[39m# self.tokenizer.save_pretrained(output_dir)\u001b[39;00m\n\u001b[1;32m    645\u001b[0m \u001b[39m# torch.save(self.args, os.path.join(output_dir, \"training_args.bin\"))\u001b[39;00m\n\u001b[1;32m    646\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave_model(model\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/simpletransformers/classification/classification_model.py:940\u001b[0m, in \u001b[0;36mClassificationModel.train\u001b[0;34m(self, train_dataloader, output_dir, multi_label, show_running_loss, eval_df, test_df, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    937\u001b[0m     loss \u001b[39m=\u001b[39m loss \u001b[39m/\u001b[39m args\u001b[39m.\u001b[39mgradient_accumulation_steps\n\u001b[1;32m    939\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mfp16:\n\u001b[0;32m--> 940\u001b[0m     scaler\u001b[39m.\u001b[39;49mscale(loss)\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m    941\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    942\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    199\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 86.00 MiB (GPU 0; 11.77 GiB total capacity; 10.36 GiB already allocated; 72.25 MiB free; 10.76 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "model = ClassificationModel(\n",
    "  'roberta', \n",
    "  'roberta-base', \n",
    "  args=model_args(), \n",
    "  num_labels=4\n",
    ")\n",
    "\n",
    "model.train_model(train_df=\"train.csv\", eval_df=\"test.csv\", **metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84dd350735c844e390f82166aac2f11f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/2224 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrafaelkallis\u001b[0m (\u001b[33mnlbse\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b558722c5c6c4c7b8e9d1cea631e522f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01666944669947649, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/rafaelkallis/Notebooks/wandb/run-20221121_140341-1xb2kxok</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nlbse/NLBSE%2723%20Issue%20Report%20Classification/runs/1xb2kxok\" target=\"_blank\">whole-vortex-20</a></strong> to <a href=\"https://wandb.ai/nlbse/NLBSE%2723%20Issue%20Report%20Classification\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb.plots.* functions are deprecated and will be removed in a future release. Please use wandb.plot.* instead.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m wandb uses only the first 10000 datapoints to create the plots.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mcc': 0.8080528003315748,\n",
       " 'precision_bug': array([0.91259603]),\n",
       " 'recall_bug': array([0.93561199]),\n",
       " 'f1_bug': array([0.9239607]),\n",
       " 'precision_feature': array([0.88941939]),\n",
       " 'recall_feature': array([0.89972915]),\n",
       " 'f1_feature': array([0.89454456]),\n",
       " 'precision_question': array([0.72115668]),\n",
       " 'recall_question': array([0.57573616]),\n",
       " 'f1_question': array([0.64029342]),\n",
       " 'precision_documentation': array([0.78247347]),\n",
       " 'recall_documentation': array([0.68410109]),\n",
       " 'f1_documentation': array([0.72998805]),\n",
       " 'precision_micro': 0.8897835862844294,\n",
       " 'recall_micro': 0.8897835862844294,\n",
       " 'f1_micro': 0.8897835862844294,\n",
       " 'eval_loss': 0.3331970460109895}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model = ClassificationModel(\n",
    "\t\"roberta\",\n",
    "\t\"outputs/<timestamp>/best_model\",\n",
    "  args=model_args(), \n",
    "  num_labels=4,\n",
    ")\n",
    "\n",
    "results, model_outputs, wrong_pred = model.eval_model(eval_df=\"test.csv\", **metrics)\n",
    "results\n",
    "\n",
    "\n",
    "\n",
    "# def batch(items, n):\n",
    "#   b = list()\n",
    "#   for i, item in enumerate(items):\n",
    "#     b.append(item)\n",
    "#     if i % n == n-1:\n",
    "#       yield b\n",
    "#       b = list()\n",
    "#   if len(b) > 0:\n",
    "#     yield b\n",
    "\n",
    "\n",
    "# # confusion matrix\n",
    "# y_true = []\n",
    "# y_pred = []\n",
    "\n",
    "# wandb.init(project=\"NLBSE 2023 Template\")\n",
    "\n",
    "# with open(\"test.csv\", newline='', encoding='utf-8') as f:\n",
    "#   label_map = {0: \"bug\", 1: \"feature\", 2: \"question\", 3: \"documentation\"}\n",
    "#   total = count_csv_rows(\"test.csv\")\n",
    "#   reader = csv.DictReader(f)\n",
    "#   for row_batch in batch(tqdm(reader, desc=\"Benchmarking Inference Performance\", total=total), n=32):\n",
    "#     # https://simpletransformers.ai/docs/classification-models/#making-predictions-with-a-classification-model\n",
    "#     preds, model_outputs = model.predict([row[\"text\"] for row in row_batch])\n",
    "\n",
    "#     y_true.extend([label_map[int(row[\"labels\"])] for row in row_batch])\n",
    "#     y_pred.extend([label_map[pred] for pred in preds])\n",
    "#     if len(y_true) >= 10_000:\n",
    "#       break\n",
    "\n",
    "# report = sklearn.metrics.classification_report(y_true, y_pred, output_dict=True)\n",
    "\n",
    "# for label in [\"bug\", \"feature\", \"question\", \"documentation\"]:\n",
    "#   # P = sklearn.metrics.precision_score(y_true, y_pred, average=None, labels=[label])[0]\n",
    "#   # R = sklearn.metrics.recall_score(y_true, y_pred, average=None, labels=[label])[0]\n",
    "#   # F1 = sklearn.metrics.f1_score(y_true, y_pred, average=None, labels=[label])[0]\n",
    "#   P = report[label][\"precision\"]\n",
    "#   R = report[label][\"recall\"]\n",
    "#   F1 = report[label][\"f1-score\"]\n",
    "#   support = report[label][\"support\"]\n",
    "#   print(f\"=*= {label} =*=\")\n",
    "#   print(f\"precision:\\t{P:.4f}\")\n",
    "#   print(f\"recall:\\t\\t{R:.4f}\")\n",
    "#   print(f\"f1 score:\\t{F1:.4f}\")\n",
    "#   print(f\"support:\\t{support}\")\n",
    "#   print()\n",
    "\n",
    "#   wandb.log({ f\"precision_{label}\": P, f\"recall_{label}\": R, f\"f1_{label}\": F1, f\"support_{label}\": support }) \n",
    "\n",
    "# # P = sklearn.metrics.precision_score(y_true, y_pred, average='micro')\n",
    "# # R = sklearn.metrics.recall_score(y_true, y_pred, average='micro')\n",
    "# # F1 = sklearn.metrics.f1_score(y_true, y_pred, average='micro')\n",
    "# P, R, F1, support = sklearn.metrics.precision_recall_fscore_support(y_true, y_pred, average='micro')\n",
    "\n",
    "# print(\"=*= micro averages =*=\")\n",
    "# print(f\"precision:\\t{P:.4f}\")\n",
    "# print(f\"recall:\\t\\t{R:.4f}\")\n",
    "# print(f\"F1 score:\\t{F1:.4f}\")\n",
    "# print(f\"precision:\\t{support}\")\n",
    "\n",
    "# wandb.log({ \"precision_micro\": P, \"recall_micro\": R, \"f1_micro\": F1, \"support_micro\": support })\n",
    "\n",
    "# wandb.join()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

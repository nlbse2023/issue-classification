{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Nov 17 10:09:02 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 520.61.05    Driver Version: 520.61.05    CUDA Version: 11.8     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0 Off |                  N/A |\n",
      "|  0%   55C    P8    15W / 170W |      0MiB / 12288MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2147483647"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import gensim\n",
    "import sklearn.metrics\n",
    "import re\n",
    "import unicodedata\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "from simpletransformers.classification import ClassificationModel, ClassificationArgs\n",
    "import wandb\n",
    "import csv\n",
    "from functools import partial\n",
    "import itertools\n",
    "import random\n",
    "import sys\n",
    "import hashlib\n",
    "\n",
    "train_file = 'nlbse23-issue-classification-train.csv'\n",
    "eval_file = 'nlbse23-issue-classification-eval.csv'\n",
    "\n",
    "csv.field_size_limit(sys.maxsize) # to avoid error: _csv.Error: field larger than field limit (131072)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_tokens(text):\n",
    "\treturn len(text.split())\n",
    "\n",
    "def count_csv_rows(csv_file):\n",
    "\twith open(csv_file, 'r', newline='') as f:\n",
    "\t\treturn sum(1 for _ in csv.DictReader(csv_file))\n",
    "\n",
    "def print_csv_preview(filename):\n",
    "\tprint(filename)\n",
    "\tprint(\"total rows\", count_csv_rows(filename))\n",
    "\tdisplay(pd.read_csv(filename, nrows=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>issue_url</th>\n",
       "      <th>issue_label</th>\n",
       "      <th>issue_created_at</th>\n",
       "      <th>issue_author_association</th>\n",
       "      <th>repository_url</th>\n",
       "      <th>issue_title</th>\n",
       "      <th>issue_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>https://api.github.com/repos/eamodio/vscode-gi...</td>\n",
       "      <td>bug</td>\n",
       "      <td>2021-01-02T18:07:30Z</td>\n",
       "      <td>NONE</td>\n",
       "      <td>https://api.github.com/repos/eamodio/vscode-gi...</td>\n",
       "      <td>Welcome screen on every editor window is very ...</td>\n",
       "      <td>I just discovered Gitlens and find the functio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>https://api.github.com/repos/binwiederhier/pco...</td>\n",
       "      <td>bug</td>\n",
       "      <td>2020-12-31T18:19:31Z</td>\n",
       "      <td>OWNER</td>\n",
       "      <td>https://api.github.com/repos/binwiederhier/pcopy</td>\n",
       "      <td>\"pcopy invite\" and \"pcopy paste abc:\" does not...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>https://api.github.com/repos/binwiederhier/pco...</td>\n",
       "      <td>bug</td>\n",
       "      <td>2021-01-03T04:33:36Z</td>\n",
       "      <td>OWNER</td>\n",
       "      <td>https://api.github.com/repos/binwiederhier/pcopy</td>\n",
       "      <td>UI: Modal overlay is half transparent, shouldn...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>https://api.github.com/repos/Sothatsit/RoyalUr...</td>\n",
       "      <td>enhancement</td>\n",
       "      <td>2020-12-25T00:46:00Z</td>\n",
       "      <td>OWNER</td>\n",
       "      <td>https://api.github.com/repos/Sothatsit/RoyalUr...</td>\n",
       "      <td>Make the loading screen scale with browser win...</td>\n",
       "      <td>Currently the loading wheel is a fixed size in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>https://api.github.com/repos/Malivil/TTT-Custo...</td>\n",
       "      <td>bug</td>\n",
       "      <td>2021-01-02T21:36:57Z</td>\n",
       "      <td>OWNER</td>\n",
       "      <td>https://api.github.com/repos/Malivil/TTT-Custo...</td>\n",
       "      <td>Spectator - Investigate a way to strip weapons...</td>\n",
       "      <td>To bring magneto stick floating</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                          issue_url  issue_label  \\\n",
       "0           0  https://api.github.com/repos/eamodio/vscode-gi...          bug   \n",
       "1           1  https://api.github.com/repos/binwiederhier/pco...          bug   \n",
       "2           2  https://api.github.com/repos/binwiederhier/pco...          bug   \n",
       "3           3  https://api.github.com/repos/Sothatsit/RoyalUr...  enhancement   \n",
       "4           4  https://api.github.com/repos/Malivil/TTT-Custo...          bug   \n",
       "\n",
       "       issue_created_at issue_author_association  \\\n",
       "0  2021-01-02T18:07:30Z                     NONE   \n",
       "1  2020-12-31T18:19:31Z                    OWNER   \n",
       "2  2021-01-03T04:33:36Z                    OWNER   \n",
       "3  2020-12-25T00:46:00Z                    OWNER   \n",
       "4  2021-01-02T21:36:57Z                    OWNER   \n",
       "\n",
       "                                      repository_url  \\\n",
       "0  https://api.github.com/repos/eamodio/vscode-gi...   \n",
       "1   https://api.github.com/repos/binwiederhier/pcopy   \n",
       "2   https://api.github.com/repos/binwiederhier/pcopy   \n",
       "3  https://api.github.com/repos/Sothatsit/RoyalUr...   \n",
       "4  https://api.github.com/repos/Malivil/TTT-Custo...   \n",
       "\n",
       "                                         issue_title  \\\n",
       "0  Welcome screen on every editor window is very ...   \n",
       "1  \"pcopy invite\" and \"pcopy paste abc:\" does not...   \n",
       "2  UI: Modal overlay is half transparent, shouldn...   \n",
       "3  Make the loading screen scale with browser win...   \n",
       "4  Spectator - Investigate a way to strip weapons...   \n",
       "\n",
       "                                          issue_body  \n",
       "0  I just discovered Gitlens and find the functio...  \n",
       "1                                                NaN  \n",
       "2                                                NaN  \n",
       "3  Currently the loading wheel is a fixed size in...  \n",
       "4                    To bring magneto stick floating  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>issue_url</th>\n",
       "      <th>issue_label</th>\n",
       "      <th>issue_created_at</th>\n",
       "      <th>issue_author_association</th>\n",
       "      <th>repository_url</th>\n",
       "      <th>issue_title</th>\n",
       "      <th>issue_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>https://api.github.com/repos/tlnagy/TIFF.jl/is...</td>\n",
       "      <td>enhancement</td>\n",
       "      <td>2020-04-07T09:08:50Z</td>\n",
       "      <td>NONE</td>\n",
       "      <td>https://api.github.com/repos/tlnagy/TIFF.jl</td>\n",
       "      <td>ERROR: KeyError: key (TIFF.SAMPLEFORMAT_INT, 0...</td>\n",
       "      <td>One more error might need to be caught.\\r\\n`4D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19</td>\n",
       "      <td>https://api.github.com/repos/tisboyo/Twitch_Bo...</td>\n",
       "      <td>enhancement</td>\n",
       "      <td>2020-11-27T07:17:21Z</td>\n",
       "      <td>OWNER</td>\n",
       "      <td>https://api.github.com/repos/tisboyo/Twitch_Bot</td>\n",
       "      <td>Add database backup to dropbox</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>https://api.github.com/repos/DrWhoCares/imgdan...</td>\n",
       "      <td>enhancement</td>\n",
       "      <td>2021-01-02T19:35:34Z</td>\n",
       "      <td>OWNER</td>\n",
       "      <td>https://api.github.com/repos/DrWhoCares/imgdanke</td>\n",
       "      <td>Add a button/method to open the Source or Outp...</td>\n",
       "      <td>Could also add a method to open up path to eac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>https://api.github.com/repos/DrWhoCares/imgdan...</td>\n",
       "      <td>bug</td>\n",
       "      <td>2021-01-02T20:55:34Z</td>\n",
       "      <td>OWNER</td>\n",
       "      <td>https://api.github.com/repos/DrWhoCares/imgdanke</td>\n",
       "      <td>Processes are being started twice</td>\n",
       "      <td>At some point I refactored a few things and en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54</td>\n",
       "      <td>https://api.github.com/repos/Bean-1/AOT/issues/3</td>\n",
       "      <td>bug</td>\n",
       "      <td>2020-12-29T15:34:35Z</td>\n",
       "      <td>OWNER</td>\n",
       "      <td>https://api.github.com/repos/Bean-1/AOT</td>\n",
       "      <td>Cannot add hp to wall</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                          issue_url  issue_label  \\\n",
       "0           6  https://api.github.com/repos/tlnagy/TIFF.jl/is...  enhancement   \n",
       "1          19  https://api.github.com/repos/tisboyo/Twitch_Bo...  enhancement   \n",
       "2          25  https://api.github.com/repos/DrWhoCares/imgdan...  enhancement   \n",
       "3          30  https://api.github.com/repos/DrWhoCares/imgdan...          bug   \n",
       "4          54   https://api.github.com/repos/Bean-1/AOT/issues/3          bug   \n",
       "\n",
       "       issue_created_at issue_author_association  \\\n",
       "0  2020-04-07T09:08:50Z                     NONE   \n",
       "1  2020-11-27T07:17:21Z                    OWNER   \n",
       "2  2021-01-02T19:35:34Z                    OWNER   \n",
       "3  2021-01-02T20:55:34Z                    OWNER   \n",
       "4  2020-12-29T15:34:35Z                    OWNER   \n",
       "\n",
       "                                     repository_url  \\\n",
       "0       https://api.github.com/repos/tlnagy/TIFF.jl   \n",
       "1   https://api.github.com/repos/tisboyo/Twitch_Bot   \n",
       "2  https://api.github.com/repos/DrWhoCares/imgdanke   \n",
       "3  https://api.github.com/repos/DrWhoCares/imgdanke   \n",
       "4           https://api.github.com/repos/Bean-1/AOT   \n",
       "\n",
       "                                         issue_title  \\\n",
       "0  ERROR: KeyError: key (TIFF.SAMPLEFORMAT_INT, 0...   \n",
       "1                     Add database backup to dropbox   \n",
       "2  Add a button/method to open the Source or Outp...   \n",
       "3                  Processes are being started twice   \n",
       "4                              Cannot add hp to wall   \n",
       "\n",
       "                                          issue_body  \n",
       "0  One more error might need to be caught.\\r\\n`4D...  \n",
       "1                                                NaN  \n",
       "2  Could also add a method to open up path to eac...  \n",
       "3  At some point I refactored a few things and en...  \n",
       "4                                                NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# download the training set if it does not exist\n",
    "if not os.path.isfile(\"github-labels-top3-803k-train.csv\"):\n",
    "  !curl \"https://tickettagger.blob.core.windows.net/datasets/github-labels-top3-803k-train.tar.gz\" | tar -xz\n",
    "\n",
    "print_csv_preview(\"github-labels-top3-803k-train.csv\")\n",
    "\n",
    "if not os.path.isfile(\"github-labels-top3-803k-test.csv\"):\n",
    "  !curl \"https://tickettagger.blob.core.windows.net/datasets/github-labels-top3-803k-test.tar.gz\" | tar -xz\n",
    "\n",
    "print_csv_preview(\"github-labels-top3-803k-test.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_sig_regex = re.compile(r'[a-zA-Z][a-zA-Z0-9_.]*\\([a-zA-Z0-9_, ]*\\)')\n",
    "issue_id_regex = re.compile(r'#[0-9]+')\n",
    "non_ascii_char_regex = re.compile(r'[^\\x00-\\x7f]')\n",
    "punctuations = '!\"$%&\\()*,/:;<=>[\\\\]^`{|}~+#@-`'\n",
    "punctuations_trans = str.maketrans(punctuations, \" \" * len(punctuations))\n",
    "\n",
    "def preprocess(text, max_tokens=None):\n",
    "  text = str(text)\n",
    "\n",
    "  # lowercase\n",
    "  # text = text.lower()\n",
    "\n",
    "  # replace function signatures\n",
    "  text = function_sig_regex.sub(\" function \", text)\n",
    "\n",
    "  # replace issue ids\n",
    "  text = issue_id_regex.sub(\" issue \", text)\n",
    "  \n",
    "  # remove html tags\n",
    "  # text = gensim.parsing.preprocessing.strip_tags(text)\n",
    "  \n",
    "  # remove punctuation\n",
    "  # text = gensim.parsing.preprocessing.strip_punctuation(text)\n",
    "  text = text.translate(punctuations_trans)\n",
    "  \n",
    "  # remove numerics\n",
    "  # text = gensim.parsing.preprocessing.strip_numeric(text)\n",
    "  \n",
    "  # remove non-ascii characters\n",
    "  text = non_ascii_char_regex.sub(\"\", text)\n",
    "  \n",
    "  text = unicodedata.normalize('NFD', text)\n",
    "  \n",
    "  # remove consecutive whitespace characters and convert tabs to spaces\n",
    "  text = gensim.parsing.preprocessing.strip_multiple_whitespaces(text)\n",
    "  \n",
    "  # text = gensim.parsing.preprocessing.strip_short(text, minsize=3)\n",
    "  \n",
    "  # text = gensim.parsing.preprocessing.remove_stopwords(text)\n",
    "  \n",
    "  # text = gensim.parsing.preprocessing.stem_text(text)\n",
    "  \n",
    "  # limit the number of tokens\n",
    "  if max_tokens is not None:\n",
    "    text = \" \".join(text.split()[:max_tokens])\n",
    "  \n",
    "  return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f6fc06b4981416b86e93f16fc611ab9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sampling CSV: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'title token frequency quantiles'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.500     7.0\n",
       "0.750    10.0\n",
       "0.800    10.0\n",
       "0.850    11.0\n",
       "0.900    13.0\n",
       "0.950    15.0\n",
       "0.990    20.0\n",
       "0.999    29.0\n",
       "Name: title, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'body token frequency quantiles'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.500      69.500\n",
       "0.750     145.000\n",
       "0.800     171.000\n",
       "0.850     207.000\n",
       "0.900     270.000\n",
       "0.950     413.150\n",
       "0.990    1212.130\n",
       "0.999    6090.088\n",
       "Name: body, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "q=[.5, .75, .8, .85, .9, .95, .99, .999]\n",
    "\n",
    "def sample_csv(file_path, n_sample):\n",
    "\tn_population = sum(1 for l in tqdm(csv.reader(open(file_path)), desc=\"Sampling CSV\")) - 1\n",
    "\tskiprows = random.sample(range(1, n_population), n_population - n_sample)\n",
    "\treturn pd.read_csv(file_path, skiprows=skiprows)\n",
    "\n",
    "sample_df = sample_csv(train_file, 10_000)\n",
    "\n",
    "display(\n",
    "\t\"title token frequency quantiles\", \n",
    "\tsample_df[\"title\"].apply(preprocess).apply(count_tokens).quantile(q=q)\n",
    ")\n",
    "display(\n",
    "\t\"body token frequency quantiles\", \n",
    "\tsample_df[\"body\"].apply(preprocess).apply(count_tokens).quantile(q=q)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_row(row):\n",
    "  # doc = \"author \" + row[\"author_association\"].lower()\n",
    "  doc = \" title \" + preprocess(row[\"title\"], max_tokens=20)\n",
    "  doc += \" body \" + preprocess(row[\"body\"], max_tokens=511-count_tokens(doc))\n",
    "\n",
    "  assert count_tokens(doc) <= 512\n",
    "\n",
    "  return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce00eb7b683c4bc09c02755df56cc429",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transform to simpletransformers format: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2eab9d25b864cbb9b76b0b70450a94c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transform to simpletransformers format: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# transform dataset into simpletransformers format\n",
    "# https://simpletransformers.ai/docs/classification-data-formats/#multi-class-classification\n",
    "\n",
    "def transform_to_simpletransformers_format(i_path, o_path):\n",
    "\tlabel_map = {\"bug\": 0, \"feature\": 1, \"question\": 2, \"documentation\": 3 }\n",
    "\n",
    "\twith open(i_path, \"r\") as i_f, open(o_path, \"w\") as o_f:\n",
    "\t\treader = csv.DictReader(i_f)\n",
    "\t\twriter = csv.DictWriter(o_f, fieldnames=[\"text\", \"labels\"])\n",
    "\t\twriter.writeheader()\n",
    "\t\tfor row in tqdm(reader, desc=\"Transform to simpletransformers format\"):\n",
    "\t\t\ttext = preprocess_row(row)\n",
    "\t\t\tlabels = label_map[row[\"labels\"]]\n",
    "\t\t\twriter.writerow({\"text\": text, \"labels\": labels})\n",
    "\n",
    "transform_to_simpletransformers_format(train_file, \"train.csv\")\n",
    "transform_to_simpletransformers_format(eval_file, \"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.decoder.weight', 'roberta.pooler.dense.bias', 'lm_head.bias', 'lm_head.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d53de8954c2043e9a0cd02fdcd953ad5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrafaelkallis\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/rafaelkallis/Notebooks/wandb/run-20221116_222715-zhys9sjp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<iframe src=\"https://wandb.ai/rafaelkallis/NLBSE%202023%20Template/runs/zhys9sjp?jupyter=true\" style=\"border:none;width:100%;height:420px;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.jupyter.IFrame at 0x7fd43c370f10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ee4aaa9de3e4e4789e52e54db410671",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 4:   0%|          | 0/9968 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/rafaelkallis/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2323: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "/home/rafaelkallis/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2323: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "/home/rafaelkallis/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2323: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%wandb\n",
    "\n",
    "model_args = ClassificationArgs()\n",
    "\n",
    "# https://simpletransformers.ai/docs/classification-specifics/#lazy-loading-data\n",
    "model_args.lazy_loading = True\n",
    "model_args.lazy_delimiter = ','\n",
    "\n",
    "# model_args.learning_rate = 1e-4 # 4e-5\n",
    "model_args.num_train_epochs = 4 # 1\n",
    "\n",
    "# model_args.max_seq_length = 512\n",
    "# batch_size = 32\n",
    "\n",
    "# model_args.max_seq_length = 200\n",
    "# batch_size = 64\n",
    "\n",
    "model_args.max_seq_length = 128\n",
    "batch_size = 128\n",
    "\n",
    "# model_args.max_seq_length = 64\n",
    "# batch_size = 256\n",
    "\n",
    "model_args.train_batch_size = batch_size\n",
    "model_args.eval_batch_size = batch_size\n",
    "\n",
    "model_args.save_steps = -1\n",
    "model_args.save_model_every_epoch = False\n",
    "\n",
    "# miscallenous\n",
    "model_args.manual_seed = 2023\n",
    "model_args.evaluate_during_training = True\n",
    "model_args.overwrite_output_dir = True\n",
    "model_args.wandb_project = \"NLBSE 2023 Template\"\n",
    "\n",
    "metrics = {\n",
    "  \"p_micro\": partial(sklearn.metrics.precision_score, average='micro'),\n",
    "  \"r_micro\": partial(sklearn.metrics.recall_score, average='micro'),\n",
    "  \"f1_micro\": partial(sklearn.metrics.f1_score, average='micro'),\n",
    "}\n",
    "\n",
    "model = ClassificationModel(\n",
    "  'roberta', \n",
    "  'roberta-base', \n",
    "  args=model_args, \n",
    "  num_labels=4\n",
    ")\n",
    "\n",
    "model.train_model(train_df=\"train.csv\", eval_df=\"test.csv\", **metrics)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

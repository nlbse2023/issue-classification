{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "import google.auth\n",
    "import csv\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "import sys\n",
    "import sklearn.model_selection\n",
    "import pandas as pd\n",
    "import hashlib\n",
    "import random\n",
    "import os\n",
    "\n",
    "csv.field_size_limit(sys.maxsize) # to avoid error: _csv.Error: field larger than field limit (131072)\n",
    "\n",
    "dataset_all_file = 'nlbse23-issue-classification-all.csv'\n",
    "dataset_file = 'nlbse23-issue-classification.csv'\n",
    "train_file = 'nlbse23-issue-classification-train.csv'\n",
    "eval_file = 'nlbse23-issue-classification-eval.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "020f2fdf1c74421590e6bd36c831414c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BigQuery: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# https://cloud.google.com/docs/authentication/application-default-credentials\n",
    "client = bigquery.Client(project=\"nlbse-issue-classification\")\n",
    "\n",
    "query = \"\"\"\n",
    "WITH\n",
    "  label_synonyms AS (\n",
    "    SELECT 'bug' AS label, synonym FROM UNNEST(['bug', 'type: bug', 'kind/bug', 'crash', 'defect', 'type-defect', 'type:bug', 'browser bug', 'fix', 'fixed', 'bugfix', 'bug fix', 'resolution: fixed', 'troubleshooting', 'type/bug', 'bug report']) AS synonym\n",
    "    UNION ALL\n",
    "    SELECT 'feature', * FROM UNNEST(['feature', 'feature request', 'enhancement', 'improvement', 'type: feature', 'type:feature', 'new feature', 'kind/feature', 'kind/enhancement'])\n",
    "    UNION ALL\n",
    "    SELECT 'question', * FROM UNNEST(['question', 'faq', 'type: question', 'type:question'])\n",
    "    UNION ALL\n",
    "    SELECT 'documentation', * FROM UNNEST(['documentation', 'docs', 'doc', 'type: documentation', 'needs documentation', 'area/documentation', 'type: docs', 'type:docs', 'needs docs', 'wiki', 'kind/documentation', 'kind/docs'])\n",
    "  ),\n",
    "  close_events AS (\n",
    "    SELECT payload\n",
    "    FROM `githubarchive.day.2022*`\n",
    "    WHERE\n",
    "      -- _TABLE_SUFFIX BETWEEN '0101' AND '0101' -- FREE\n",
    "      -- _TABLE_SUFFIX BETWEEN '0101' AND '0131' -- $\n",
    "      _TABLE_SUFFIX BETWEEN '0101' AND '0930' -- $$$ $$$ $$$\n",
    "      AND type = 'IssuesEvent'\n",
    "      AND JSON_EXTRACT_SCALAR(payload, '$.action') = 'closed'\n",
    "      AND JSON_EXTRACT_SCALAR(payload, '$.issue.body') != 'null'\n",
    "  ),\n",
    "  nested_labels AS (\n",
    "    SELECT\n",
    "      ARRAY(\n",
    "        SELECT LOWER(JSON_EXTRACT_SCALAR(label_payload, '$.name'))\n",
    "        FROM UNNEST(JSON_EXTRACT_ARRAY(payload, '$.issue.labels')) AS label_payload\n",
    "      ) AS labels,\n",
    "      payload\n",
    "    FROM close_events\n",
    "  ),\n",
    "  synonymized_labels AS (\n",
    "    SELECT\n",
    "      ARRAY(\n",
    "        SELECT DISTINCT label_synonyms.label -- bug, feature, question, documentation\n",
    "        FROM UNNEST(nested_labels.labels) AS label, label_synonyms\n",
    "        WHERE label = label_synonyms.synonym\n",
    "        ORDER BY label_synonyms.label\n",
    "      ) AS labels,\n",
    "      payload\n",
    "    FROM nested_labels\n",
    "  ),\n",
    "  filtered_labels AS (\n",
    "    SELECT labels, payload\n",
    "    FROM synonymized_labels\n",
    "    WHERE ARRAY_LENGTH(labels) = 1 -- exactly 1 label\n",
    "  ),\n",
    "  concatenated_labels AS (\n",
    "    SELECT ARRAY_TO_STRING(labels, ',') AS labels, payload\n",
    "    FROM filtered_labels\n",
    "  )\n",
    "SELECT\n",
    "  JSON_EXTRACT_SCALAR(payload, '$.issue.id') AS id,\n",
    "  labels,\n",
    "  JSON_EXTRACT_SCALAR(payload, '$.issue.title') AS title,\n",
    "  JSON_EXTRACT_SCALAR(payload, '$.issue.body') AS body,\n",
    "  JSON_EXTRACT_SCALAR(payload, '$.issue.author_association') AS author_association\n",
    "FROM concatenated_labels\n",
    "\"\"\"\n",
    "\n",
    "query_job = client.query(query)\n",
    "rows = query_job.result()\n",
    "\n",
    "with open(dataset_all_file, \"w\", newline='', encoding='utf-8') as f:\n",
    "  fieldnames = [\"id\", \"labels\", \"title\", \"body\", \"author_association\"]\n",
    "  writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "  writer.writeheader()\n",
    "  for row in tqdm(rows, desc=\"BigQuery\", smoothing=0):\n",
    "    writer.writerow({\n",
    "      **row,\n",
    "      \"title\": row[\"title\"].replace(\"\\0\", \"\"),\n",
    "      \"body\": row[\"body\"].replace(\"\\0\", \"\"),\n",
    "    })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nlbse23-issue-classification-all.csv\n",
      "total rows 1555561\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>labels</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>author_association</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1199051804</td>\n",
       "      <td>documentation</td>\n",
       "      <td>setting a logging Handler name</td>\n",
       "      <td>BPO | [43058](https://bugs.python.org/issue430...</td>\n",
       "      <td>MANNEQUIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1199074324</td>\n",
       "      <td>documentation</td>\n",
       "      <td>Improve documentation for typing._GenericAlias</td>\n",
       "      <td>BPO | [46589](https://bugs.python.org/issue465...</td>\n",
       "      <td>MANNEQUIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1199022454</td>\n",
       "      <td>documentation</td>\n",
       "      <td>Description of '\\w' behavior is vague in `re` ...</td>\n",
       "      <td>BPO | [38566](https://bugs.python.org/issue385...</td>\n",
       "      <td>MANNEQUIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1199028356</td>\n",
       "      <td>documentation</td>\n",
       "      <td>add docstrings to functions in pdb module</td>\n",
       "      <td>BPO | [39278](https://bugs.python.org/issue392...</td>\n",
       "      <td>MANNEQUIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1199055394</td>\n",
       "      <td>documentation</td>\n",
       "      <td>Documentation needs to declare CalledProcessEr...</td>\n",
       "      <td>BPO | [43635](https://bugs.python.org/issue436...</td>\n",
       "      <td>MANNEQUIN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id         labels  \\\n",
       "0  1199051804  documentation   \n",
       "1  1199074324  documentation   \n",
       "2  1199022454  documentation   \n",
       "3  1199028356  documentation   \n",
       "4  1199055394  documentation   \n",
       "\n",
       "                                               title  \\\n",
       "0                     setting a logging Handler name   \n",
       "1     Improve documentation for typing._GenericAlias   \n",
       "2  Description of '\\w' behavior is vague in `re` ...   \n",
       "3          add docstrings to functions in pdb module   \n",
       "4  Documentation needs to declare CalledProcessEr...   \n",
       "\n",
       "                                                body author_association  \n",
       "0  BPO | [43058](https://bugs.python.org/issue430...          MANNEQUIN  \n",
       "1  BPO | [46589](https://bugs.python.org/issue465...          MANNEQUIN  \n",
       "2  BPO | [38566](https://bugs.python.org/issue385...          MANNEQUIN  \n",
       "3  BPO | [39278](https://bugs.python.org/issue392...          MANNEQUIN  \n",
       "4  BPO | [43635](https://bugs.python.org/issue436...          MANNEQUIN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def count_csv_rows(filename):\n",
    "\twith open(filename, \"r\", newline='', encoding='utf-8') as f:\n",
    "\t\treturn sum(1 for _ in csv.DictReader(f))\n",
    "\n",
    "def dataset_stats(filename):\n",
    "\tprint(filename)\n",
    "\tprint(\"total rows\", count_csv_rows(filename))\n",
    "\tdisplay(pd.read_csv(filename, nrows=5))\n",
    "\n",
    "dataset_stats(dataset_all_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ce1b3d925974cc29b78934ca5b6b73f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Counting labels:   0%|          | 0/1555561 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nlbse23-issue-classification-all.csv\n",
      "label counts {'bug': 801069, 'feature': 589064, 'question': 91373, 'documentation': 74055}\n",
      "label distribution {'bug': 0.515, 'feature': 0.379, 'question': 0.059, 'documentation': 0.048}\n"
     ]
    }
   ],
   "source": [
    "def label_stats(filename):\n",
    "\tlabel_count = {\"bug\": 0, \"feature\": 0, \"question\": 0, \"documentation\": 0}\n",
    "\twith open(filename, \"r\", newline='', encoding='utf-8') as f:\n",
    "\t\tfor row in tqdm(csv.DictReader(f), desc=\"Counting labels\", total=count_csv_rows(filename)):\n",
    "\t\t\tlabel_count[row[\"labels\"]] += 1\n",
    "\tprint(filename)\n",
    "\tprint(\"label counts\", label_count)\n",
    "\ttotal = sum(label_count.values())\n",
    "\tprint(\"label distribution\", {k: round(v / total, 3) for k, v in label_count.items()})\n",
    "\n",
    "label_stats(dataset_all_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "import fasttext\n",
    "import gensim\n",
    "\n",
    "# https://fasttext.cc/docs/en/language-identification.html\n",
    "# download the training set if it does not exist\n",
    "if not os.path.isfile(\"lid.176.bin\"):\n",
    "  !curl \"https://dl.fbaipublicfiles.com/fasttext/supervised-models/lid.176.bin\" -o \"lid.176.bin\"\n",
    "\n",
    "model = fasttext.load_model(\"lid.176.bin\")\n",
    "\n",
    "def identify_language(text):\n",
    "  text = gensim.parsing.strip_multiple_whitespaces(text)\n",
    "  return model.predict(text)[0][0][9:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f3d46fc08024d99ad48c2dd913d636c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Language stats:   0%|          | 0/1555561 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nlbse23-issue-classification-all.csv\n",
      "language counts {'en': 1418201, 'zh': 30229, 'id': 1842, 'de': 8177, 'pt': 8759, 'ru': 10913, 'gl': 12, 'nl': 2233, 'it': 2269, 'ko': 29715, 'es': 13338, 'fr': 8013, 'fa': 287, 'ja': 13697, 'uk': 1305, 'hr': 92, 'tt': 11, 'ms': 92, 'pl': 821, 'hu': 451, 'el': 90, 'sv': 386, 'cs': 806, 'tr': 544, 'sah': 9, 'ro': 58, 'ar': 84, 'no': 519, 'is': 15, 'vi': 728, 'sr': 247, 'da': 260, 'sh': 38, 'wuu': 4, 'ca': 149, 'he': 67, 'la': 37, 'th': 253, 'kn': 23, 'fi': 211, 'lv': 3, 'ceb': 46, 'hy': 8, 'sl': 58, 'mk': 23, 'bg': 19, 'et': 38, 'ml': 9, 'ka': 4, 'lt': 35, 'sk': 86, 'eo': 9, 'ba': 12, 'mn': 14, 'be': 12, 'eu': 15, 'tl': 20, 'bs': 20, 'war': 2, 'ta': 6, 'oc': 14, 'az': 7, 'hi': 20, 'uz': 13, 'ur': 6, 'sq': 7, 'te': 5, 'qu': 1, 'af': 3, 'ku': 1, 'pms': 2, 'my': 2, 'cv': 1, 'lb': 2, 'mr': 4, 'io': 1, 'ast': 1, 'gu': 2, 'si': 3, 'nds': 2, 'bn': 8, 'jv': 2, 'als': 1, 'ht': 1, 'gv': 1, 'tg': 3, 'sco': 1, 'fy': 1, 'cy': 3, 'arz': 3, 'nn': 6, 'km': 1, 'pa': 1, 'sa': 2, 'ps': 1, 'ne': 1, 'ug': 1, 'yue': 1, 'gom': 1, 'ky': 1}\n",
      "language distribution {'en': 0.912, 'zh': 0.019, 'id': 0.001, 'de': 0.005, 'pt': 0.006, 'ru': 0.007, 'gl': 0.0, 'nl': 0.001, 'it': 0.001, 'ko': 0.019, 'es': 0.009, 'fr': 0.005, 'fa': 0.0, 'ja': 0.009, 'uk': 0.001, 'hr': 0.0, 'tt': 0.0, 'ms': 0.0, 'pl': 0.001, 'hu': 0.0, 'el': 0.0, 'sv': 0.0, 'cs': 0.001, 'tr': 0.0, 'sah': 0.0, 'ro': 0.0, 'ar': 0.0, 'no': 0.0, 'is': 0.0, 'vi': 0.0, 'sr': 0.0, 'da': 0.0, 'sh': 0.0, 'wuu': 0.0, 'ca': 0.0, 'he': 0.0, 'la': 0.0, 'th': 0.0, 'kn': 0.0, 'fi': 0.0, 'lv': 0.0, 'ceb': 0.0, 'hy': 0.0, 'sl': 0.0, 'mk': 0.0, 'bg': 0.0, 'et': 0.0, 'ml': 0.0, 'ka': 0.0, 'lt': 0.0, 'sk': 0.0, 'eo': 0.0, 'ba': 0.0, 'mn': 0.0, 'be': 0.0, 'eu': 0.0, 'tl': 0.0, 'bs': 0.0, 'war': 0.0, 'ta': 0.0, 'oc': 0.0, 'az': 0.0, 'hi': 0.0, 'uz': 0.0, 'ur': 0.0, 'sq': 0.0, 'te': 0.0, 'qu': 0.0, 'af': 0.0, 'ku': 0.0, 'pms': 0.0, 'my': 0.0, 'cv': 0.0, 'lb': 0.0, 'mr': 0.0, 'io': 0.0, 'ast': 0.0, 'gu': 0.0, 'si': 0.0, 'nds': 0.0, 'bn': 0.0, 'jv': 0.0, 'als': 0.0, 'ht': 0.0, 'gv': 0.0, 'tg': 0.0, 'sco': 0.0, 'fy': 0.0, 'cy': 0.0, 'arz': 0.0, 'nn': 0.0, 'km': 0.0, 'pa': 0.0, 'sa': 0.0, 'ps': 0.0, 'ne': 0.0, 'ug': 0.0, 'yue': 0.0, 'gom': 0.0, 'ky': 0.0}\n"
     ]
    }
   ],
   "source": [
    "def language_stats(filename):\n",
    "\t# compute language statistsics\n",
    "\tlanguage_count = {}\n",
    "\twith open(filename, \"r\", newline='', encoding='utf-8') as f:\n",
    "\t\trows = csv.DictReader(f)\n",
    "\t\ttexts = (f\"{row['title']} {row['body']}\" for row in rows)\n",
    "\t\tlangs = (identify_language(text) for text in texts)\n",
    "\t\tfor lang in tqdm(langs, desc=\"Language stats\", total=count_csv_rows(filename)):\n",
    "\t\t\tif lang not in language_count:\n",
    "\t\t\t\tlanguage_count[lang] = 0\n",
    "\t\t\tlanguage_count[lang] += 1\n",
    "\tprint(filename)\n",
    "\tprint(\"language counts\", language_count)\n",
    "\ttotal = sum(language_count.values())\n",
    "\tprint(\"language distribution\", {k: round(v / total, 3) for k, v in language_count.items()})\n",
    "\n",
    "language_stats(dataset_all_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79f05ff5a4894ecbaa296f1a219dae10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filtering EN:   0%|          | 0/1555561 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def filter_en(filename_csv_in, filename_csv_out):\n",
    "\twith open(filename_csv_in, \"r\", newline='', encoding='utf-8') as f_in, open(filename_csv_out, \"w\", newline='', encoding='utf-8') as f_out:\n",
    "\t\treader = csv.DictReader(f_in)\n",
    "\t\twriter = csv.DictWriter(f_out, fieldnames=reader.fieldnames)\n",
    "\t\twriter.writeheader()\n",
    "\t\tfor row in tqdm(reader, desc=\"Filtering EN\", total=count_csv_rows(filename_csv_in)):\n",
    "\t\t\tif identify_language(f\"{row['title']} {row['body']}\") == \"en\":\n",
    "\t\t\t\twriter.writerow(row)\n",
    "\n",
    "filter_en(dataset_all_file, dataset_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e70e6eb7e4474ba5888e193dc98489d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Counting labels:   0%|          | 0/1418201 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nlbse23-issue-classification.csv\n",
      "label counts {'bug': 745732, 'feature': 525013, 'question': 84538, 'documentation': 62918}\n",
      "label distribution {'bug': 0.526, 'feature': 0.37, 'question': 0.06, 'documentation': 0.044}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "label_stats(dataset_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Evaluation Split\n",
    "\n",
    "We split the dataset into training and evaluation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f343792f1b04fa9b86a2c176fe4e527",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Splitting:   0%|          | 0/1418201 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nlbse23-issue-classification-train.csv\n",
      "total rows 1275881\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>labels</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>author_association</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1199051804</td>\n",
       "      <td>documentation</td>\n",
       "      <td>setting a logging Handler name</td>\n",
       "      <td>BPO | [43058](https://bugs.python.org/issue430...</td>\n",
       "      <td>MANNEQUIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1199074324</td>\n",
       "      <td>documentation</td>\n",
       "      <td>Improve documentation for typing._GenericAlias</td>\n",
       "      <td>BPO | [46589](https://bugs.python.org/issue465...</td>\n",
       "      <td>MANNEQUIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1199022454</td>\n",
       "      <td>documentation</td>\n",
       "      <td>Description of '\\w' behavior is vague in `re` ...</td>\n",
       "      <td>BPO | [38566](https://bugs.python.org/issue385...</td>\n",
       "      <td>MANNEQUIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1199028356</td>\n",
       "      <td>documentation</td>\n",
       "      <td>add docstrings to functions in pdb module</td>\n",
       "      <td>BPO | [39278](https://bugs.python.org/issue392...</td>\n",
       "      <td>MANNEQUIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1199055394</td>\n",
       "      <td>documentation</td>\n",
       "      <td>Documentation needs to declare CalledProcessEr...</td>\n",
       "      <td>BPO | [43635](https://bugs.python.org/issue436...</td>\n",
       "      <td>MANNEQUIN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id         labels  \\\n",
       "0  1199051804  documentation   \n",
       "1  1199074324  documentation   \n",
       "2  1199022454  documentation   \n",
       "3  1199028356  documentation   \n",
       "4  1199055394  documentation   \n",
       "\n",
       "                                               title  \\\n",
       "0                     setting a logging Handler name   \n",
       "1     Improve documentation for typing._GenericAlias   \n",
       "2  Description of '\\w' behavior is vague in `re` ...   \n",
       "3          add docstrings to functions in pdb module   \n",
       "4  Documentation needs to declare CalledProcessEr...   \n",
       "\n",
       "                                                body author_association  \n",
       "0  BPO | [43058](https://bugs.python.org/issue430...          MANNEQUIN  \n",
       "1  BPO | [46589](https://bugs.python.org/issue465...          MANNEQUIN  \n",
       "2  BPO | [38566](https://bugs.python.org/issue385...          MANNEQUIN  \n",
       "3  BPO | [39278](https://bugs.python.org/issue392...          MANNEQUIN  \n",
       "4  BPO | [43635](https://bugs.python.org/issue436...          MANNEQUIN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nlbse23-issue-classification-eval.csv\n",
      "total rows 142320\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>labels</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>author_association</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1199053386</td>\n",
       "      <td>documentation</td>\n",
       "      <td>A possible misleading expression in the Virtua...</td>\n",
       "      <td>BPO | [43319](https://bugs.python.org/issue433...</td>\n",
       "      <td>MANNEQUIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1255069635</td>\n",
       "      <td>bug</td>\n",
       "      <td>[BUG] a valid `gameName` in the `create a new ...</td>\n",
       "      <td>**Describe the bug**\\r\\nIn the `create a new p...</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1089772715</td>\n",
       "      <td>feature</td>\n",
       "      <td>How to check if a certain entity still exists?</td>\n",
       "      <td>During a bug in my own code I noticed that the...</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000928729</td>\n",
       "      <td>feature</td>\n",
       "      <td>chose the timezone in dbeaver option</td>\n",
       "      <td>Dbeaver 21.2.0\\r\\n\\r\\nFor all version DBeaver,...</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1300011093</td>\n",
       "      <td>bug</td>\n",
       "      <td>[Issue]: Multiple Versions of a Movie not work...</td>\n",
       "      <td>### Please describe your bug\\n\\nThe doc at htt...</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id         labels  \\\n",
       "0  1199053386  documentation   \n",
       "1  1255069635            bug   \n",
       "2  1089772715        feature   \n",
       "3  1000928729        feature   \n",
       "4  1300011093            bug   \n",
       "\n",
       "                                               title  \\\n",
       "0  A possible misleading expression in the Virtua...   \n",
       "1  [BUG] a valid `gameName` in the `create a new ...   \n",
       "2     How to check if a certain entity still exists?   \n",
       "3               chose the timezone in dbeaver option   \n",
       "4  [Issue]: Multiple Versions of a Movie not work...   \n",
       "\n",
       "                                                body author_association  \n",
       "0  BPO | [43319](https://bugs.python.org/issue433...          MANNEQUIN  \n",
       "1  **Describe the bug**\\r\\nIn the `create a new p...               NONE  \n",
       "2  During a bug in my own code I noticed that the...               NONE  \n",
       "3  Dbeaver 21.2.0\\r\\n\\r\\nFor all version DBeaver,...               NONE  \n",
       "4  ### Please describe your bug\\n\\nThe doc at htt...               NONE  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def split_dataset(filename_in, filename_out_train, filename_out_test, train_percentage):\n",
    "\tseed = int(hashlib.sha256(\"nlbse2023\".encode('utf8')).hexdigest(), 16)\n",
    "\tr = random.Random(seed)\n",
    "\n",
    "\twith open(filename_in, \"r\", newline='') as f, open(filename_out_train, \"w\", newline='') as f_train, open(filename_out_test, \"w\", newline='') as f_test:\n",
    "\t\tfieldnames = [\"id\", \"labels\", \"title\", \"body\", \"author_association\"]\n",
    "\t\twriter_train = csv.DictWriter(f_train, fieldnames=fieldnames)\n",
    "\t\twriter_train.writeheader()\n",
    "\t\twriter_test = csv.DictWriter(f_test, fieldnames=fieldnames)\n",
    "\t\twriter_test.writeheader()\n",
    "\t\ttotal = count_csv_rows(filename_in)\n",
    "\t\tis_train_gen = (r.random() < 0.9 for _ in range(total))\n",
    "\t\tfor row, is_train in tqdm(zip(csv.DictReader(f), is_train_gen), desc=\"Splitting\", total=total, smoothing=0):\n",
    "\n",
    "\t\t\tif is_train:\n",
    "\t\t\t\twriter_train.writerow(row)\n",
    "\t\t\telse:\n",
    "\t\t\t\twriter_test.writerow(row)\n",
    "\n",
    "split_dataset(dataset_file, train_file, eval_file, train_percentage=0.9)\n",
    "\n",
    "dataset_stats(train_file)\n",
    "dataset_stats(eval_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
